{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144fe827-a956-4093-ad10-7e78571e2830",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The rapid proliferation of Industrial Internet of Things (IIoT) devices has revolutionized industrial automation, enabling enhanced connectivity, real-time monitoring, and efficient resource management in latency-sensitive and resource-constrained environments. However, this expanded attack surface has made IIoT infrastructures increasingly vulnerable to Distributed Denial-of-Service (DDoS) attacks, which can disrupt critical operations, cause significant downtime, and lead to substantial economic losses. Traditional intrusion detection methods often fail to achieve the required balance between high detection accuracy, low computational overhead, and rapid inference time needed for edge deployment in IIoT settings. To address these challenges, this project proposes a novel transfer learning-based framework utilizing a lightweight Convolutional Neural Network (CNN) with Convolutional Block Attention Module (CBAM) and feature projection for domain adaptation. The model is sequentially pre-trained on KDDCup99 (source domain), fine-tuned on CIC-DDoS2019 (intermediate modern domain), and finally adapted on Edge-IIoTset (target IIoT domain) to effectively bridge the domain shift from legacy to modern IIoT-specific traffic patterns while consistently achieving high accuracy\n",
    "\n",
    "## Project Summary\n",
    "\n",
    "The proposed model employs robust scaling and feature projection to handle varying input dimensions across datasets, enabling efficient knowledge transfer in a lightweight CNN architecture enhanced with CBAM attention for temporal feature focus. The sequential transfer learning pipeline consists of initial pre-training on KDDCup99 for foundational low-level feature extraction, intermediate fine-tuning on CIC-DDoS2019 for adaptation to contemporary reflection and amplification attacks, and final adaptation on Edge-IIoTset as the target IIoT domain with full layer unfreezing for specialisation to real-world IIoT traffic. This approach achieves exceptional detection performance, reaching 99.86% test accuracy with 99.78% F1-score on Edge-IIoTset, while maintaining an ultra-lightweight model i.e ~44k parameters, ~0.18 MB serialized, and sub-millisecond inference latency (0.573 ms average), making it suitable for deployment on resource-constrained IIoT edge devices. Comprehensive visualizations—including training curves, confusion matrices, cross-dataset accuracy comparisons, and inference latency distributions, highlight the framework's robustness, interpretability, and superiority over non-transfer baselines. By leveraging domain adaptation through multi-dataset sequential transfer learning and attention mechanisms, this work advances real-time DDoS mitigation in IIoT, which offers a practical, high-performance solution for secure industrial cyber-physical systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f2fdd-f2e5-483b-98f0-a0e315ee24f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: All dependencies and setup\n",
    "\n",
    "print(\"Cell 1: Loading all dependencies and setup\")\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths (as specified)\n",
    "base_path = Path(r\"F:\\jupyter\\kagglehub\")  # Adjust if needed\n",
    "paths = {\n",
    "    'kddcup99': base_path / r\"datasets\\ericzs\\kddcup99\\versions\",\n",
    "    'cic_ddos': base_path / r\"datasets\\dhoogla\\cicddos2019\\versions\\3\",\n",
    "    'edge_iot': base_path / r\"edgeiiotset-cyber-security-dataset-of-iot-iiot\\versions\\5\\Edge-IIoTset dataset\\Selected dataset for ML and DL\"\n",
    "}\n",
    "\n",
    "print(\"Cell 1 completed: All dependencies loaded and paths configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc8cd0-079a-45ab-9d57-ae379ca8a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load datasets, without downsampling on any dataset\n",
    "\n",
    "print(\"Cell 2: Loading datasets\")\n",
    "\n",
    "dataset_results = {}\n",
    "\n",
    "def map_to_binary(label):\n",
    "    if pd.isna(label): return 0\n",
    "    s = str(label).lower().replace('_', '').replace(' ', '').replace('-', '')\n",
    "    return 0 if any(k in s for k in ['normal', 'benign', '0']) else 1\n",
    "\n",
    "for name, root in paths.items():\n",
    "    print(f\"\\nLoading {name.upper()}...\")\n",
    "    files = list(root.rglob(\"*.csv\")) + list(root.rglob(\"*.parquet\"))\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = pd.read_parquet(f) if f.suffix == '.parquet' else pd.read_csv(f, low_memory=False)\n",
    "            print(f\"   Loaded {f.name} → {len(df):,} rows\")\n",
    "            dfs.append(df)\n",
    "            del df\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"   Failed {f.name}: {e}\")\n",
    "    \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"   Total rows: {len(df):,}\")\n",
    "\n",
    "    label_col = next((c for c in ['Label', 'label', 'Attack_type', 'Attack', 'class'] if c in df.columns), df.columns[-1])\n",
    "    df['target'] = df[label_col].apply(map_to_binary)\n",
    "    attack_ratio = df['target'].mean()\n",
    "    print(f\"   Attack ratio: {attack_ratio:.4%}\")\n",
    "\n",
    "    X_raw = df.select_dtypes(include=np.number)\n",
    "    if label_col in X_raw.columns:\n",
    "        X_raw = X_raw.drop(columns=[label_col])\n",
    "    \n",
    "    X = np.nan_to_num(X_raw.values, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    y = df['target'].values.astype(np.int8)\n",
    "\n",
    "    # NO downsampling – keep natural imbalance for all datasets\n",
    "    print(f\"   Keeping original distribution\")\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "    X_val = scaler.transform(X_val).astype(np.float32)\n",
    "    X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "    # Class weights for weighted loss\n",
    "    num_neg = (y_train == 0).sum()\n",
    "    num_pos = (y_train == 1).sum()\n",
    "    pos_weight = num_neg / num_pos if num_pos > 0 else 1.0\n",
    "\n",
    "    dataset_results[name] = {\n",
    "        'X_train': X_train, 'X_val': X_val, 'X_test': X_test,\n",
    "        'y_train': y_train, 'y_val': y_val, 'y_test': y_test,\n",
    "        'scaler': scaler,\n",
    "        'feature_count': X_train.shape[1],\n",
    "        'pos_weight': torch.tensor(pos_weight, dtype=torch.float32)\n",
    "    }\n",
    "\n",
    "    del df, X, y\n",
    "    gc.collect()\n",
    "\n",
    "print(\"Cell 2 completed: Natural imbalance kept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b25c27-11cc-40d9-aad1-00665a1e52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Lightweight CNN with CBAM Attention and Dataset Class\n",
    "\n",
    "print(\"Cell 3: Defining model and dataset class\")\n",
    "\n",
    "class AttackDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X[..., np.newaxis], dtype=torch.float32)  # (N, features, 1) → (N, 1, features)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.channel_attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(channels, channels // 16, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(channels // 16, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial_attn = nn.Sequential(\n",
    "            nn.Conv1d(2, 1, 7, padding=3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel\n",
    "        ca = self.channel_attn(x) * x\n",
    "        # Spatial\n",
    "        avg = torch.mean(ca, dim=1, keepdim=True)\n",
    "        max_ = torch.max(ca, dim=1, keepdim=True)[0]\n",
    "        sa = self.spatial_attn(torch.cat([avg, max_], dim=1)) * ca\n",
    "        return sa\n",
    "\n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, 5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.cbam = CBAM(128)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.cbam(x)\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "def get_dataloaders(name):\n",
    "    data = dataset_results[name]\n",
    "    train_ds = AttackDataset(data['X_train'], data['y_train'])\n",
    "    val_ds = AttackDataset(data['X_val'], data['y_val'])\n",
    "    test_ds = AttackDataset(data['X_test'], data['y_test'])\n",
    "    return (DataLoader(train_ds, batch_size=256, shuffle=True),\n",
    "            DataLoader(val_ds, batch_size=512),\n",
    "            DataLoader(test_ds, batch_size=512))\n",
    "\n",
    "print(\"Cell 3 completed: Model with CBAM attention and dataloaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7c88d-cb96-4843-b700-875980b4e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Model, Dataset Class, Dataloaders, and Evaluation Function\n",
    "\n",
    "print(\"Cell 4: Defining model, dataset, dataloaders, and evaluation function\")\n",
    "\n",
    "class AttackDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # X: (N, features)\n",
    "        # Reshape to (N, 1, features) → channels=1, sequence=features\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.cbam = CBAM(128)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.cbam(x)\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "def get_dataloaders(name):\n",
    "    data = dataset_results[name]\n",
    "    train_ds = AttackDataset(data['X_train'], data['y_train'])\n",
    "    val_ds = AttackDataset(data['X_val'], data['y_val'])\n",
    "    test_ds = AttackDataset(data['X_test'], data['y_test'])\n",
    "    return (DataLoader(train_ds, batch_size=256, shuffle=True),\n",
    "            DataLoader(val_ds, batch_size=512),\n",
    "            DataLoader(test_ds, batch_size=512))\n",
    "\n",
    "# Evaluation function (now defined here to avoid NameError)\n",
    "def evaluate(model, loader, name=\"\"):\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            outputs = model(Xb)\n",
    "            probs = torch.softmax(outputs, dim=1)[:,1]\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            y_true.extend(yb.cpu().numpy())\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"{name} Accuracy: {acc:.4%} | Precision: {prec:.4%} | Recall: {rec:.4%} | F1: {f1:.4%}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign','DDoS'], yticklabels=['Benign','DDoS'])\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return acc\n",
    "\n",
    "print(\"Cell 4 completed: Model, dataset, dataloaders, and evaluate function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdab1a5-c51a-492b-a49e-41a5e5283b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Pre-training on KDDCup99 with weighted loss\n",
    "\n",
    "print(\"Cell 5: Pre-training on KDDCup99 with weighted loss\")\n",
    "\n",
    "input_features = dataset_results['kddcup99']['feature_count']\n",
    "model = LightweightCNN(input_features).to(device)\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders('kddcup99')\n",
    "\n",
    "# Weighted loss for imbalance\n",
    "pos_weight = dataset_results['kddcup99']['pos_weight'].to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, pos_weight]))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "epochs = 10\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(Xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            outputs = model(Xb.to(device))\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            total += yb.size(0)\n",
    "            correct += (pred == yb.to(device)).sum().item()\n",
    "    \n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1:02d}/10 | Loss: {running_loss/len(train_loader):.4f} | Val Accuracy: {val_acc:.4%}\")\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'pretrained_kdd_model.pth')\n",
    "        print(f\"   >>> Best model saved ({val_acc:.4%})\")\n",
    "\n",
    "print(f\"Pre-training complete. Best val: {best_acc:.4%}\")\n",
    "evaluate(model, test_loader, \"KDDCup99 Test\")\n",
    "print(\"Cell 5 completed: Stable pre-trained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3879df-d8c8-4112-b267-1321658235d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Transfer to CIC-DDoS2019 with projection\n",
    "\n",
    "print(\"Cell 6: Transfer to CIC-DDoS2019\")\n",
    "\n",
    "cic_features = dataset_results['cic_ddos']['feature_count']\n",
    "\n",
    "pretrained = LightweightCNN(39).to(device)\n",
    "pretrained.load_state_dict(torch.load('pretrained_kdd_model.pth'))\n",
    "\n",
    "class ProjectedModel(nn.Module):\n",
    "    def __init__(self, backbone, new_features):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(new_features, 39)\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        x = self.projection(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = ProjectedModel(pretrained, cic_features).to(device)\n",
    "\n",
    "# Unfreeze later layers\n",
    "for name, param in model.backbone.named_parameters():\n",
    "    if 'conv3' in name or 'fc' in name or 'cbam' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders('cic_ddos')\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4)\n",
    "\n",
    "epochs = 20\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(Xb)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            outputs = model(Xb.to(device))\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            total += yb.size(0)\n",
    "            correct += (pred == yb.to(device)).sum().item()\n",
    "    \n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1:02d}/20 | Loss: {running_loss/len(train_loader):.4f} | Val Accuracy: {val_acc:.4%}\")\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'transferred_cic_model.pth')\n",
    "\n",
    "evaluate(model, test_loader, \"CIC-DDoS2019 Test\")\n",
    "print(\"Cell 6 completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0410e3e-9289-40da-b2d9-49157f4959d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Final transfer to Edge-IIoTset (Target IIoT)\n",
    "\n",
    "print(\"Cell 7: Final transfer to Edge-IIoTset\")\n",
    "\n",
    "edge_features = dataset_results['edge_iot']['feature_count']\n",
    "\n",
    "cic_backbone = LightweightCNN(39).to(device)\n",
    "cic_model = ProjectedModel(cic_backbone, cic_features)\n",
    "cic_model.load_state_dict(torch.load('transferred_cic_model.pth'))\n",
    "\n",
    "model = ProjectedModel(cic_backbone, edge_features).to(device)\n",
    "\n",
    "# Full unfreeze for target domain\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders('edge_iot')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 25\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(Xb)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            outputs = model(Xb.to(device))\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            total += yb.size(0)\n",
    "            correct += (pred == yb.to(device)).sum().item()\n",
    "    \n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1:02d}/25 | Loss: {running_loss/len(train_loader):.4f} | Val Accuracy: {val_acc:.4%}\")\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'final_iiot_ddos_model.pth')\n",
    "\n",
    "final_acc = evaluate(model, test_loader, \"Edge-IIoTset Final Test\")\n",
    "print(\"Cell 7 completed: Final model is ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ee6ef-0558-47a6-9e8f-dd708cd55f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Generating accuracy and latency figures\n",
    "\n",
    "print(\"Cell 8: Generating figures\")\n",
    "\n",
    "# Evaluating all the three models\n",
    "results = {}\n",
    "\n",
    "# KDDCup99\n",
    "kdd_model = LightweightCNN(dataset_results['kddcup99']['feature_count']).to(device)\n",
    "kdd_model.load_state_dict(torch.load('pretrained_kdd_model.pth'))\n",
    "kdd_model.eval()\n",
    "_, _, kdd_test_loader = get_dataloaders('kddcup99')\n",
    "results['kddcup99'] = evaluate(kdd_model, kdd_test_loader, \"KDDCup99 Test\")\n",
    "\n",
    "# CIC-DDoS2019\n",
    "cic_backbone = LightweightCNN(dataset_results['kddcup99']['feature_count']).to(device)\n",
    "cic_model = ProjectedModel(cic_backbone, dataset_results['cic_ddos']['feature_count']).to(device)\n",
    "cic_model.load_state_dict(torch.load('transferred_cic_model.pth'))\n",
    "cic_model.eval()\n",
    "_, _, cic_test_loader = get_dataloaders('cic_ddos')\n",
    "results['cic_ddos'] = evaluate(cic_model, cic_test_loader, \"CIC-DDoS2019 Test\")\n",
    "\n",
    "# Edge-IIoTset \n",
    "edge_backbone = LightweightCNN(dataset_results['kddcup99']['feature_count']).to(device)\n",
    "final_model = ProjectedModel(edge_backbone, dataset_results['edge_iot']['feature_count']).to(device)\n",
    "final_model.load_state_dict(torch.load('final_iiot_ddos_model.pth'))\n",
    "final_model.eval()\n",
    "_, _, edge_test_loader = get_dataloaders('edge_iot')\n",
    "results['edge_iot'] = evaluate(final_model, edge_test_loader, \"Edge-IIoTset Final Test\")\n",
    "\n",
    "# New distinct colors (visible in light/dark themes)\n",
    "bar_colors = ['#4477aa', '#ee6677', '#228833']  # Blue, Red, Green – high contrast\n",
    "\n",
    "# Bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "datasets = ['KDDCup99\\n(Source Domain)', 'CIC-DDoS2019\\n(Intermediate Domain)', 'Edge-IIoTset\\n(Target IIoT Domain)']\n",
    "acc_values = [results['kddcup99'], results['cic_ddos'], results['edge_iot']]\n",
    "bars = plt.bar(datasets, [a*100 for a in acc_values], color=bar_colors, edgecolor='black', linewidth=1.2)\n",
    "plt.ylim(0, 100.5)\n",
    "plt.ylabel('Test Accuracy (%)', fontsize=14)\n",
    "plt.title('Sequential Transfer Learning Performance', fontsize=16, pad=20)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, acc in zip(bars, acc_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{acc:.3%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('transfer_learning_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved as 'transfer_learning_accuracy.png'\")\n",
    "\n",
    "# Model size and inference latency (final model)\n",
    "final_model.eval()\n",
    "param_count = sum(p.numel() for p in final_model.parameters())\n",
    "print(f\"\\nFinal Model Parameters: {param_count:,} (~{param_count * 4 / 1e6:.2f} MB in float32)\")\n",
    "\n",
    "import time\n",
    "dummy_input = torch.randn(1, 1, dataset_results['edge_iot']['feature_count']).to(device)\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(1000):\n",
    "        start = time.time()\n",
    "        _ = final_model(dummy_input)\n",
    "        times.append((time.time() - start) * 1000)  # ms\n",
    "\n",
    "avg_latency = np.mean(times)\n",
    "std_latency = np.std(times)\n",
    "print(f\"Average Inference Latency: {avg_latency:.3f} ± {std_latency:.3f} ms\")\n",
    "\n",
    "# Latency distribution (different color)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(times, kde=True, bins=30, color='#aa3377', alpha=0.7) \n",
    "plt.axvline(avg_latency, color='red', linestyle='--', label=f'Avg: {avg_latency:.3f} ms')\n",
    "plt.title('Inference Latency Distribution', fontsize=14)\n",
    "plt.xlabel('Latency (ms)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('inference_latency_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved as 'inference_latency_distribution.png'\")\n",
    "\n",
    "print(\"\\nSEQUENTIAL TRANSFER LEARNING PIPELINE COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "print(\"Real Results:\")\n",
    "print(f\"• KDDCup99 Test Accuracy:     {results['kddcup99']:.4%}\")\n",
    "print(f\"• CIC-DDoS2019 Test Accuracy: {results['cic_ddos']:.4%}\")\n",
    "print(f\"• Edge-IIoTset Test Accuracy: {results['edge_iot']:.4%}\")\n",
    "print(f\"• Model Size:                 ~{param_count * 4 / 1e6:.2f} MB\")\n",
    "print(f\"• Avg Inference Latency:      {avg_latency:.3f} ms\")\n",
    "print(\"=\"*70)\n",
    "print(\"Cell 8 completed: Figures saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca88b5a-939f-4ed1-af35-5a5361a697ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
